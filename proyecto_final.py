# -*- coding: utf-8 -*-
"""Proyecto FInal.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XzCIP6qbwInLNQN0MnoW89QVgl9K_jd4
"""

#Transferencia de Aprendizaje / Transfer Learning
#Crear nuestro propio conjunto de datos

!unzip capacitorespreparados/capacitorespreparados.zip -d capacitorespreparados

!unzip resistenciaspreparadas/resistenciaspreparados.zip -d resistenciaspreparados

!unzip transistorespreparados/transistorespreparados.zip -d transistorespreparados

#borrar los archivos .zip
!rm -rf resistenciaspreparadas/resistenciaspreparados.zip
!rm -rf transistorespreparados/resistenciaspreparados.zip
!rm -rf capacitorespreparados/capacitorespreparados.zip

import os

if not os.path.exists('dataset'):
    os.makedirs('dataset')
os.system('cp -r resistenciaspreparados dataset/resistenciaspreparados')
os.system('cp -r transistorespreparados dataset/transistorespreparados')
os.system('cp -r capacitorespreparados dataset/capacitorespreparados')

import shutil
import os

if os.path.exists('dataset'):
    shutil.rmtree('dataset')
os.makedirs('dataset')
os.system('cp -r resistenciaspreparados dataset/resistenciaspreparados')
os.system('cp -r transistorespreparados dataset/transistorespreparados')
os.system('cp -r capacitorespreparados dataset/capacitorespreparados')

#Crear un set de datos (ya no en memoria)

!mkdir dataset
!cp -r resistenciaspreparados dataset/resistenciaspreparados
!cp -r transistorespreparados dataset/transistorespreparados
!cp -r capacitorespreparados dataset/capacitorespreparados

!ls /content/capacitorespreparados/capacitorespreparados | wc -l # cantidad de archivos
!ls /content/transistorespreparados/transistorespreparados | wc -l # cantidad de archivos
!ls /content/resistenciaspreparados/resistenciaspreparados | wc -l # cantidad de archivos

#Aumento de datos
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np

#Crear el dataset generador
datagen = ImageDataGenerator(   #darselo al modelo mientras
    rescale=1. / 255,  #normalizar
    rotation_range = 10,  #rota un poco las imagenes
    width_shift_range=0.15,  #mueve las imagens en el ancho (izq o derecha)
    height_shift_range = 0.15, #mueve las imagens en el largo (arr o abajo)
    shear_range = 5, #zoom a las imagenes (un poco)
    zoom_range = [0.7, 1.3],  #minimo acercamiento y acercamiento maximo de 1.3
    validation_split = 0.2 #quiero que el 20% de las imagenes sean generadas
)


#Generadores para set de datos de entrenamiento y de pruebas
data_gen_entrenamiento = datagen.flow_from_directory("/content/dataset",
                                                     target_size=(224,224), #tamaño de las imagenes
                                                     batch_size=32, shuffle=True,
                                                     subset="training")

data_gen_pruebas = datagen.flow_from_directory("/content/dataset",
                                                     target_size=(224,224),
                                                     batch_size=32, shuffle=True, #mezcle las imagenes constantemente
                                                     subset="validation") #este termina con el 80%

import matplotlib.pyplot as plt

#ver como quedaron las imagenes
for imagenes, etiquetas in data_gen_entrenamiento: #data_gen_entrenamiento es un generador
  for i in range(10):  #conjunto de 10 imagenes
    plt.subplot(2, 5, i+1) #solo vere 2x5 imagenes
    plt.imshow(imagenes[i])
  break #solo van a entrar una vez las imagenes, ya tratadas
plt.show()

#Redes convolucionales
import tensorflow as tf
import tensorflow_hub as hub

#descargamos modelo entrenado por google
url ="https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4"
mobilenetv2 = hub.KerasLayer(url, input_shape=(224, 224, 3)) #descargar el modelo

#Importante
#Congelar las capas
mobilenetv2.trainable = False #no queremos que se entrene mas
#que los pesos y sesgos se queden como estan

modelo = tf.keras.Sequential([
    mobilenetv2,
    tf.keras.layers.Dense(3, activation="softmax") #solo agregamos una capa mas (con 3 unidades (tenedores, cuchillos, cucharas))
])
#entrenar modelo

modelo.compile(
    optimizer="adam",
    loss="categorical_crossentropy",
    metrics=["accuracy"]
)  #compilar

EPOCAS = 24
entrenamiento = modelo.fit(
    data_gen_entrenamiento, epochs=EPOCAS, batch_size=32,
    validation_data=data_gen_pruebas
) #entrenamiento

#Graficas de precisión
acc = entrenamiento.history['accuracy']
val_acc = entrenamiento.history[ 'val_accuracy']

loss = entrenamiento.history['loss']
val_loss = entrenamiento.history['val_loss']

rango_epocas = range(len(acc))




plt.figure(figsize=(8,8))
plt.subplot (1,2,1)
plt.plot(rango_epocas, acc, label='Precisión Entrenamiento')
plt.plot(rango_epocas, val_acc, label='Precisión Pruebas')
plt.legend(loc='lower right')
plt.title( 'Precisión de entrenamiento y pruebas')

plt.subplot (1,2,2)
plt.plot(rango_epocas, loss, label='Pérdida de entrenamiento')
plt.plot(rango_epocas, val_loss, label='Pérdida de pruebas')
plt.legend (loc='upper right')
plt.title('Pérdida de entrenamiento y pruebas')
plt.show( )

from PIL import Image
import cv2

def categorizar(ruta): #funcion para probar que el modelo lo hace bien
  img = Image.open(ruta)
  img = img.convert("RGB") #tomar la imagen como si tuviera 3 canales de color
  img = np.array(img).astype(float)/255 #normalizar a un arreglo numpy luego de volver numeros flotantes

  img = cv2.resize(img, (224, 224)) #la vuelve 224 x 224
  prediccion = modelo.predict(img.reshape(-1, 224, 224, 3)) #trasnformacion de la estructura del arreglo
  return np.argmax(prediccion[0], axis=-1) #solo devuelve el valor maximo para las dos clases

  #la neurona del animal al maximo y la del otro al 0 y viceversa
  #0 es babuino y 1 es jirafa

ruta = "resistenciabella.jpeg"
prediccion = categorizar(ruta)
print(prediccion)

ruta = "transistorbello.jpeg"
prediccion = categorizar(ruta)
print(prediccion)

ruta = "capacitor.jpeg"
prediccion = categorizar(ruta)
print(prediccion)

#IMAGEN A PROCESAR